{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb113df3-2019-4cbf-8205-910ac3097418",
   "metadata": {},
   "source": [
    "Alex Thoennes  \n",
    "May 30, 2022  \n",
    "CS583 Final Project  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a2879-24c6-4653-9de3-870d32a15d34",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30def9ef-d7d7-45be-a474-e7a6df566db8",
   "metadata": {},
   "source": [
    "This file creates the average and image databases. These databases are written to csv and pickle files which are used to make this program more portable. Without those two files, all images would be required to run the mosaic program which would consume a lot of disk space. If you wish to create the csv and pickle file, then download the Visual Genome dataset parts 1 and 2 here(https://visualgenome.org/api/v0/api_home.html) and extract them to a directory called images(data/images/). This program automatically downloads the cifar100 data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad3836-c095-4b76-83b2-060a6d8a6e89",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c83b37-e658-4cfb-93cd-73485c1c67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 14:15:50.170068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97aa85-11d7-486f-81cb-1f1d5101cc80",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc6a4cc-bd85-4e09-93a2-e209ed21efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function determiens if an image is a grayscale image.\n",
    "opencv reads grayscale images as 3 channels and copies the first layer twice.\n",
    "\"\"\"\n",
    "def is_grayscale(r, g, b):\n",
    "    return b.all() == g.all() and b.all() == r.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a012b218-ca02-4fb5-b161-352d9e49252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parses the visual genome dataset and adds each image's filename\n",
    "and average RGB values to a dataframe which is returned\n",
    "\"\"\"\n",
    "def parse_visual_genome(avg_df):\n",
    "    # all images should be extracted to this path\n",
    "    data_path = 'data/images/'\n",
    "\n",
    "    # iterate over all images, read them in and split them,\n",
    "    # then calulate their average RGB and add the data to the dataframe\n",
    "    for image in os.listdir(data_path):\n",
    "            full_path = data_path + image\n",
    "            img = cv2.imread(full_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                b,g,r = cv2.split(img)\n",
    "                if not is_grayscale(r, g, b):\n",
    "                    avg_dict = {'Filename':image, 'R Average':np.mean(r), 'G Average':np.mean(g), 'B Average':np.mean(b)}\n",
    "                    avg_df = avg_df.append(avg_dict, ignore_index=True)\n",
    "\n",
    "    return avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c11540f-16ec-427c-b77c-6d4e50bbfbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parses the cifar100 dataset and adds each image's filename\n",
    "and average RGB values to a dataframe which is returned\n",
    "\"\"\"\n",
    "def parse_cifar_100(avg_df, images, file_prefix, ext):\n",
    "    # this is used to label the images in both the train test splits\n",
    "    img_idx = 0\n",
    "    \n",
    "    for image in images:\n",
    "        # get file name\n",
    "        filename = file_prefix+str(img_idx)+ext\n",
    "        # save cifar img\n",
    "        pil_img = Image.fromarray(np.uint8(image))\n",
    "        \n",
    "        # obtain channels\n",
    "        r,g,b = pil_img.split()\n",
    "        \n",
    "        # calculate and save avgs\n",
    "        avg_dict = {'Filename':filename, 'R Average':np.mean(r), 'G Average':np.mean(g), 'B Average':np.mean(b)}\n",
    "        \n",
    "        # append to df\n",
    "        avg_df = avg_df.append(avg_dict, ignore_index=True)\n",
    "        \n",
    "        # move to next file\n",
    "        img_idx += 1\n",
    "        \n",
    "    return avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1072717c-4f37-42b0-b467-c7a07bc784f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "takes all images and writes them to a pickle file for portability\n",
    "\"\"\"\n",
    "def compile_img_database(avg_df):\n",
    "    img_df = pd.DataFrame(columns=['Filename','R', 'G','B'])\n",
    "    \n",
    "    for file in avg_df['Filename']:\n",
    "        image = cv2.imread('data/images/'+file)\n",
    "        b,g,r = cv2.split(image)\n",
    "        img_dict = {'Filename':file, 'R':r.astype(np.uint8), 'G':g.astype(np.uint8), 'B':b.astype(np.uint8)}\n",
    "        img_df = img_df.append(img_dict, ignore_index=True)\n",
    "    \n",
    "    img_df.to_pickle('data/img_database.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e4e6c2-d2a8-41b6-a609-402ea8d449d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "takes the database of RGB averages and writes it to a csv file for portability\n",
    "\"\"\"\n",
    "def compile_avg_database(avg_df):\n",
    "    # create the dataframe\n",
    "    avg_df = pd.DataFrame(columns=['Filename','R Average', 'G Average','B Average'])\n",
    "    \n",
    "    # parse the VG data\n",
    "    avg_df = parse_visual_genome(avg_df)\n",
    "    \n",
    "    # parse the CIFAR data\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "    avg_df = parse_cifar_100(avg_df, x_train, 'cifar_train_', '.jpeg')\n",
    "    avg_df = parse_cifar_100(avg_df, x_test, 'cifar_test_', '.jpeg')\n",
    "    \n",
    "    avg_df.to_csv('data/avg_database.csv', index=False)\n",
    "    \n",
    "    return avg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18d58e-c105-4a46-9ef6-481aa84a076c",
   "metadata": {},
   "source": [
    "# Database Creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdb98407-1774-40be-bd13-6e6de41781e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = pd.DataFrame(columns=['Filename', 'R Average', 'G Average', 'B Average'])\n",
    "\n",
    "# create the database of average RGB values\n",
    "avg_df = compile_avg_database(avg_df)\n",
    "avg_df = pd.read_csv('data/avg_database.csv')\n",
    "\n",
    "# create the database of raw image data\n",
    "compile_img_database(avg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140e8d1-5aa5-47f2-a2c7-9d0bd79f44bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_mosaic",
   "language": "python",
   "name": "video_mosaic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
